{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44161e68-2522-4058-b13a-6b1a69aad0a2",
   "metadata": {},
   "source": [
    "### main search of Sign language video for each word in the sentence \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f85400c-6f3c-4f4b-8777-999cfa4afa55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://dic.ttrs.or.th/video/view/62d920d866b04b724ea396dd \n",
    "\n",
    "\n",
    "# these videos cant be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e72ff4-f2a5-474d-b357-ad37bc898c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://my-project-0004-346516-pytorch112kagglewbi-us-central1/...\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.storage.buckets.create) HTTPError 409: Your previous request to create the named bucket succeeded and you already own it.\n",
      "mkdir: cannot create directory ‘content’: File exists\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"us-central1\"\n",
    "\n",
    "UNIQUE_PREFIX = socket.gethostname()\n",
    "UNIQUE_PREFIX = re.sub('[^A-Za-z0-9]+', '', UNIQUE_PREFIX)\n",
    "\n",
    "UID = UNIQUE_PREFIX\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-{UNIQUE_PREFIX}-{LOCATION}\"\n",
    "\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud storage buckets create {BUCKET_URI} --project={PROJECT_ID} --location={LOCATION}\n",
    "\n",
    "!mkdir content\n",
    "!rm -r content/clips/\n",
    "!mkdir content/clips/\n",
    "!rm -r content/frames/\n",
    "!mkdir content/frames/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff213bf7-f08e-4d24-9b90-3fe5b04ae89a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://my-project-0004-346516-pytorch112kagglewbi-us-central1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71bd12e1-8c67-4bb2-b2c8-2cb9c48cc012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from google.cloud import aiplatform\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Project Setup (Replace placeholders)\n",
    "BUCKET_URI = BUCKET_URI\n",
    "BUCKET_URI_ME = f\"{BUCKET_URI}/embeddings/\"\n",
    "LOCATION = 'us-central1'\n",
    "PROJECT_ID =PROJECT_ID\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Video Folder Path\n",
    "video_folder = \"./videos\" \n",
    "i =1\n",
    "# Data Collection\n",
    "shots_data = []\n",
    "for filename in os.listdir(video_folder):\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(video_folder, filename)\n",
    "        clip = VideoFileClip(video_path)\n",
    "\n",
    "        # Frame Extraction (Adjust as needed)\n",
    "        frame = clip.get_frame(0)  \n",
    "\n",
    "        shots_data.append({\n",
    "            'id': f\"{filename}_{i}\",  # Unique ID\n",
    "            'start_time': 0, \n",
    "            'end_time': clip.duration,  # Duration in seconds\n",
    "            'clip_name': filename,\n",
    "            'frame_name': f\"{filename}_{i}.jpg\", \n",
    "            'description': os.path.splitext(filename)[0], # Filename as description\n",
    "            'embedding': \"test_embedding\"\n",
    "        })\n",
    "\n",
    "# DataFrame Creation\n",
    "shots_df = pd.DataFrame(shots_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4729aa-2f6c-4e3f-a9b4-a5a94f0fd171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be_careful_bk.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.34</td>\n",
       "      <td>be_careful_bk.mp4</td>\n",
       "      <td>be_careful_bk.mp4_1.jpg</td>\n",
       "      <td>be_careful_bk</td>\n",
       "      <td>test_embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sailor_bk.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>sailor_bk.mp4</td>\n",
       "      <td>sailor_bk.mp4_1.jpg</td>\n",
       "      <td>sailor_bk</td>\n",
       "      <td>test_embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.74</td>\n",
       "      <td>should.mp4</td>\n",
       "      <td>should.mp4_1.jpg</td>\n",
       "      <td>should</td>\n",
       "      <td>test_embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>today.mp4</td>\n",
       "      <td>today.mp4_1.jpg</td>\n",
       "      <td>today</td>\n",
       "      <td>test_embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afternoon.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>afternoon.mp4</td>\n",
       "      <td>afternoon.mp4_1.jpg</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>test_embedding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  start_time  end_time          clip_name  \\\n",
       "0  be_careful_bk.mp4_1           0      2.34  be_careful_bk.mp4   \n",
       "1      sailor_bk.mp4_1           0      2.90      sailor_bk.mp4   \n",
       "2         should.mp4_1           0      4.74         should.mp4   \n",
       "3          today.mp4_1           0      2.16          today.mp4   \n",
       "4      afternoon.mp4_1           0      1.84      afternoon.mp4   \n",
       "\n",
       "                frame_name    description       embedding  \n",
       "0  be_careful_bk.mp4_1.jpg  be_careful_bk  test_embedding  \n",
       "1      sailor_bk.mp4_1.jpg      sailor_bk  test_embedding  \n",
       "2         should.mp4_1.jpg         should  test_embedding  \n",
       "3          today.mp4_1.jpg          today  test_embedding  \n",
       "4      afternoon.mp4_1.jpg      afternoon  test_embedding  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shots_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12f6197-cbae-4a72-a3e6-0647904a9105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingModel\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2480e98-7bdd-4c41-b2c2-11f059b22a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingsList = []\n",
    "for description in shots_df['description']:  # Iterate directly over the description column\n",
    "    embeddings = text_embedding_model.get_embeddings([description]) \n",
    "    text_embedding = [embedding.values for embedding in embeddings][0]\n",
    "    embeddingsList.append(text_embedding)\n",
    "\n",
    "shots_df[\"embedding\"] = embeddingsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22e9edc5-0c6d-4355-b10c-81fb50508bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be_careful_bk.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.34</td>\n",
       "      <td>be_careful_bk.mp4</td>\n",
       "      <td>be_careful_bk.mp4_1.jpg</td>\n",
       "      <td>be_careful_bk</td>\n",
       "      <td>[0.034322116523981094, 0.01670219749212265, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sailor_bk.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>sailor_bk.mp4</td>\n",
       "      <td>sailor_bk.mp4_1.jpg</td>\n",
       "      <td>sailor_bk</td>\n",
       "      <td>[0.009677188470959663, 0.02842838689684868, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.74</td>\n",
       "      <td>should.mp4</td>\n",
       "      <td>should.mp4_1.jpg</td>\n",
       "      <td>should</td>\n",
       "      <td>[0.06107574701309204, 0.005806656088680029, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>today.mp4</td>\n",
       "      <td>today.mp4_1.jpg</td>\n",
       "      <td>today</td>\n",
       "      <td>[-0.005217599682509899, 0.023500807583332062, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afternoon.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>afternoon.mp4</td>\n",
       "      <td>afternoon.mp4_1.jpg</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>[-0.001268067047931254, -0.030368715524673462,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  start_time  end_time          clip_name  \\\n",
       "0  be_careful_bk.mp4_1           0      2.34  be_careful_bk.mp4   \n",
       "1      sailor_bk.mp4_1           0      2.90      sailor_bk.mp4   \n",
       "2         should.mp4_1           0      4.74         should.mp4   \n",
       "3          today.mp4_1           0      2.16          today.mp4   \n",
       "4      afternoon.mp4_1           0      1.84      afternoon.mp4   \n",
       "\n",
       "                frame_name    description  \\\n",
       "0  be_careful_bk.mp4_1.jpg  be_careful_bk   \n",
       "1      sailor_bk.mp4_1.jpg      sailor_bk   \n",
       "2         should.mp4_1.jpg         should   \n",
       "3          today.mp4_1.jpg          today   \n",
       "4      afternoon.mp4_1.jpg      afternoon   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.034322116523981094, 0.01670219749212265, 0....  \n",
       "1  [0.009677188470959663, 0.02842838689684868, 0....  \n",
       "2  [0.06107574701309204, 0.005806656088680029, -0...  \n",
       "3  [-0.005217599682509899, 0.023500807583332062, ...  \n",
       "4  [-0.001268067047931254, -0.030368715524673462,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shots_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c2fc13-3d6a-47ac-a4ba-d137b90daf20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JSONL Export\n",
    "jsonl_string = shots_df[['id','start_time','end_time','clip_name', 'frame_name', \"description\", \"embedding\"]].to_json(orient=\"records\", lines=True)\n",
    "with open(f\"./videodata.json\", \"w\") as f:\n",
    "    f.write(jsonl_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b929ceba-e36d-443b-b224-47354048b28d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://videodata.json [Content-Type=application/json]...\n",
      "/ [1 files][101.9 KiB/101.9 KiB]                                                \n",
      "Operation completed over 1 objects/101.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp videodata.json {BUCKET_URI_ME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f6896-cd61-4d23-97b2-de6c1d8f4f85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52a385b-15d5-4fbc-8578-e9d81c4fbd43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/255766800726/locations/us-central1/indexes/2219337832386789376/operations/5222191121060331520\n",
      "MatchingEngineIndex created. Resource name: projects/255766800726/locations/us-central1/indexes/2219337832386789376\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/255766800726/locations/us-central1/indexes/2219337832386789376')\n"
     ]
    }
   ],
   "source": [
    "# create Index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=f\"vs-feature-index-{UID}\",\n",
    "    contents_delta_uri=BUCKET_URI_ME,\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=10,\n",
    "    project = PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b233cac-869f-45ce-ad46-73fd5d11adcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Index Endpoint and deploy the Index\n",
    "To use the Index, you need to create an Index Endpoint. It works as a server instance accepting query requests for your Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a3f7e4-e2fb-481d-a874-7e994af3b99c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232/operations/4935368119792173056\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232')\n"
     ]
    }
   ],
   "source": [
    "# create IndexEndpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=f\"sing-lang-testing-lh2-{UID}\", public_endpoint_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2c493-3470-471e-ac28-99149dd72f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232/operations/274142505463709696\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f830537ba00> \n",
       "resource name: projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID = f\"sing_lang_testing_lh2_{UID}\"\n",
    "# deploy the Index to the Index Endpoint\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e4b75-fb5e-445d-b2ab-7a6758cd00aa",
   "metadata": {},
   "source": [
    "### get index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35de32-30ad-4d0c-8565-411723432def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ryptography (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of platformdirs: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/platformdirs-3.11.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of prometheus-client: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/prometheus_client-0.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of pytz: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/pytz-2023.3.post1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ryptography (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm -q\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14596136-1837-4fb6-b989-e1983181d2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import Image as vision_model_Image\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel\n",
    "REGION = LOCATION = \"us-central1\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999e9b7-0a18-4483-bc72-7a73237ebeda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my-project-0004-346516'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index_endpoint_id= '9221168615552712704' ##'2987475519047467008' #'8368299436119425024'\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f346f07-aa3a-4198-9f1d-14397cfccffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_index_name = my_index._gca_resource.name\n",
    "my_index_display_name = my_index.display_name\n",
    "my_index_id = my_index.name.split('/')[-1]\n",
    "\n",
    "my_index_endpoint_name = my_index_endpoint._gca_resource.name\n",
    "my_index_endpoint_display_name = my_index_endpoint.display_name\n",
    "my_index_endpoint_id = my_index_endpoint.name.split('/')[-1]\n",
    "my_index_endpoint_public_domain = my_index_endpoint.public_endpoint_domain_name\n",
    "\n",
    "my_index = aiplatform.MatchingEngineIndex(my_index_name)\n",
    "\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b710556-b675-431f-9dbe-7f8a9024ed06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94718965.us-central1-255766800726.vdb.vertexai.goog\n",
      "projects/255766800726/locations/us-central1/indexEndpoints/5811943697633247232\n",
      "sing_lang_testing_lh2_pytorch112kagglewbi\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "\n",
    "# Set variables for the current deployed index.\n",
    "API_ENDPOINT=my_index_endpoint_public_domain\n",
    "INDEX_ENDPOINT=my_index_endpoint_name\n",
    "\n",
    "indexendpoint_id=UNIQUE_PREFIX\n",
    "\n",
    "DEPLOYED_INDEX_ID=\"sing_lang_testing_lh2_\" + indexendpoint_id\n",
    "neighbor_count = 3\n",
    "\n",
    "print(API_ENDPOINT)\n",
    "print(INDEX_ENDPOINT)\n",
    "print(DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f69445-df92-4863-95b0-6c03c3793efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model=\"text-embedding-004\", model_name=\"text-embedding-004\")\n",
    "\n",
    "text_embedding_model = embeddings #TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233aabd-10f8-4711-ac1d-82248aef6713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set your query\n",
    "query = \"rain\"\n",
    "\n",
    "#Set the number of results you want\n",
    "neighbor_count = 2\n",
    "\n",
    "test_embeddings = embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ff7f7-d792-4ed4-ba76-2f9975bf9d95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor_count 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>clip_name</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>today.mp4</td>\n",
       "      <td>today.mp4_1.jpg</td>\n",
       "      <td>today</td>\n",
       "      <td>[-0.005217599682509899, 0.023500807583332062, ...</td>\n",
       "      <td>0.412280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afternoon.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>afternoon.mp4</td>\n",
       "      <td>afternoon.mp4_1.jpg</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>[-0.001268067047931254, -0.030368715524673462,...</td>\n",
       "      <td>0.515925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pouring_rain.mp4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>pouring_rain.mp4</td>\n",
       "      <td>pouring_rain.mp4_1.jpg</td>\n",
       "      <td>pouring_rain</td>\n",
       "      <td>[0.00017337207100354135, -0.05368410795927048,...</td>\n",
       "      <td>0.843044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  start_time  end_time         clip_name  \\\n",
       "3         today.mp4_1           0      2.16         today.mp4   \n",
       "4     afternoon.mp4_1           0      1.84     afternoon.mp4   \n",
       "7  pouring_rain.mp4_1           0      3.30  pouring_rain.mp4   \n",
       "\n",
       "               frame_name   description  \\\n",
       "3         today.mp4_1.jpg         today   \n",
       "4     afternoon.mp4_1.jpg     afternoon   \n",
       "7  pouring_rain.mp4_1.jpg  pouring_rain   \n",
       "\n",
       "                                           embedding  distance  \n",
       "3  [-0.005217599682509899, 0.023500807583332062, ...  0.412280  \n",
       "4  [-0.001268067047931254, -0.030368715524673462,...  0.515925  \n",
       "7  [0.00017337207100354135, -0.05368410795927048,...  0.843044  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Configure Vector Search client\n",
    "client_options = {\n",
    "  \"api_endpoint\": API_ENDPOINT\n",
    "}\n",
    "vector_search_client = aiplatform_v1.MatchServiceClient(\n",
    "  client_options=client_options,\n",
    ")\n",
    "# Build FindNeighborsRequest object\n",
    "datapoint = aiplatform_v1.IndexDatapoint(\n",
    "  feature_vector=test_embeddings\n",
    ")\n",
    "\n",
    "query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "  datapoint=datapoint,\n",
    "  # The number of nearest neighbors to be retrieved\n",
    "  neighbor_count=neighbor_count\n",
    ")\n",
    "\n",
    "request = aiplatform_v1.FindNeighborsRequest(\n",
    "  index_endpoint=INDEX_ENDPOINT,\n",
    "  deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "  # Request can have multiple queries\n",
    "  queries=[query],\n",
    "  return_full_datapoint=False,\n",
    ")\n",
    "\n",
    "# Execute the request\n",
    "response = vector_search_client.find_neighbors(request)\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "print('neighbor_count', neighbor_count)\n",
    "\n",
    "shots_df['distance'] = None\n",
    "\n",
    "for i in range(0,neighbor_count):\n",
    "    x=response.nearest_neighbors[0]\n",
    "\n",
    "    df_match = shots_df.loc[shots_df['id'] == str(x.neighbors[i].datapoint.datapoint_id) ]\n",
    "    df_match['distance'] = x.neighbors[i].distance\n",
    "\n",
    "    # Append the matching rows to the new DataFrame\n",
    "    df_new = pd.concat([df_new, df_match])\n",
    "    \n",
    "\n",
    "# Print the new DataFrame\n",
    "df_sorted = df_new.sort_values(by=\"distance\", ascending=True)\n",
    "print(display(df_sorted))\n",
    "\n",
    "#Export DataFrame to CSV file for reference\n",
    "# df_new.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f96637-576a-4a67-b228-4713fb5505e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['today.mp4', 'afternoon.mp4', 'pouring_rain.mp4']\n"
     ]
    }
   ],
   "source": [
    "# clipNames = []\n",
    "\n",
    "# for i in df_sorted['clip_name']:\n",
    "#     clipNames.append(i)\n",
    "    \n",
    "# #Display the clips     \n",
    "# print(clipNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c91f9-2816-4c99-a6d7-5c263ac76e74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pouring_rain.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import vertexai\n",
    "\n",
    "# from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "# # TODO(developer): Update project_id and location\n",
    "# vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# Given the following query:\n",
    "# Query: {query}\n",
    "# Search Results: {clipNames}\n",
    "\n",
    "# Select the best matching reult and only give out the final search result as an answer.\n",
    "# \"\"\"\n",
    "\n",
    "# response = model.generate_content(\n",
    "#     [ prompt]\n",
    "# )\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42425329-b881-466b-bc58-83a5354357c7",
   "metadata": {},
   "source": [
    "### Searching the full sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d659a3-b635-494a-8e96-c3a84dd7d3fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "\n",
    "query = \"today pouring rain in thailand\"\n",
    "query = \"sailor should be careful\"\n",
    "\n",
    "neighbor_count = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9a98c85-1c84-4281-8df2-652111d3a673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word sailor ['sailor_v1.mp4', 'sailor.mp4']\n",
      "sailor.mp4 \n",
      "\n",
      "word should ['be_careful.mp4', 'should.mp4']\n",
      "be_careful.mp4 \n",
      "\n",
      "word be ['be_careful.mp4', 'be_careful_bk.mp4']\n",
      "be_careful.mp4 \n",
      "\n",
      "word careful ['be_careful_bk.mp4', 'be_careful.mp4']\n",
      "be_careful.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the query into individual words\n",
    "query_words = query.split()\n",
    "stop_words = [\"are\", \"of\", \"the\", \"an\", \"in\", \"an\", \"being\", \"a\", \"so\", \"an\"]\n",
    "filtered_words = [word for word in query_words if word.lower() not in stop_words]\n",
    "\n",
    "video_list = []\n",
    "\n",
    "for word in filtered_words:\n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    test_embeddings = embeddings.embed_query(word)\n",
    "\n",
    "    client_options = {\n",
    "        \"api_endpoint\": API_ENDPOINT\n",
    "    }\n",
    "    vector_search_client = aiplatform_v1.MatchServiceClient(\n",
    "        client_options=client_options,\n",
    "    )\n",
    "\n",
    "    datapoint = aiplatform_v1.IndexDatapoint(\n",
    "        feature_vector=test_embeddings\n",
    "    )\n",
    "\n",
    "    query_embeded = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "        datapoint=datapoint,\n",
    "        neighbor_count=neighbor_count\n",
    "    )\n",
    "\n",
    "    request = aiplatform_v1.FindNeighborsRequest(\n",
    "        index_endpoint=INDEX_ENDPOINT,\n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        queries=[query_embeded],\n",
    "        return_full_datapoint=False,\n",
    "    )\n",
    "\n",
    "    response = vector_search_client.find_neighbors(request)\n",
    "\n",
    "    for i in range(0, neighbor_count):\n",
    "        x = response.nearest_neighbors[0]\n",
    "        df_match = shots_df.loc[shots_df['id'] == str(x.neighbors[i].datapoint.datapoint_id)]\n",
    "        df_match['distance'] = x.neighbors[i].distance\n",
    "        df_new = pd.concat([df_new, df_match])\n",
    "\n",
    "    df_sorted = df_new.sort_values(by=\"distance\", ascending=True)\n",
    "    # print(display(df_sorted))\n",
    "\n",
    "    clipNames = []\n",
    "\n",
    "    for i in df_sorted['clip_name']:\n",
    "        clipNames.append(i)\n",
    "\n",
    "    print(\"word\",word,clipNames)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Given the following query:\n",
    "    Query: {query_words}\n",
    "    Search Results: {clipNames}\n",
    "\n",
    "    Select the best matching word with the action mp4 file and only give out the final search result as an answer, else give NA\n",
    "    \n",
    "    follow the logig of few_shot_examples : - \n",
    "    hello : hello.mp4\n",
    "    welcome : welcome.mp4\n",
    "    paris : paris.mp4\n",
    "    forecast : forecast.mp4\n",
    "    by : NA\n",
    "    in : NA\n",
    "    of : NA\n",
    "    \n",
    "    DO NOT give Anything else just the final match.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # print('prompt',prompt)\n",
    "    response = model.generate_content([prompt])\n",
    "\n",
    "    print(response.text)\n",
    "    video_list.append(str(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "482ee0b0-b9a6-40df-959f-c2c16c520d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sailor.mp4', 'be_careful.mp4']\n"
     ]
    }
   ],
   "source": [
    "# video_list\n",
    "from itertools import groupby\n",
    "\n",
    "cleaned_video_list = [item.strip() for item in video_list]\n",
    "unique_video_list = [k for k, _ in groupby(cleaned_video_list)]\n",
    "\n",
    "print(unique_video_list) \n",
    "\n",
    "final_video_list = unique_video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37ab412f-5ea1-4de3-a7c7-870f541ae58d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3.7-0+deb11u1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 10 (Debian 10.2.1-6)\n",
      "  configuration: --prefix=/usr --extra-version=0+deb11u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x558f26e1d280] Auto-inserting h264_mp4toannexb bitstream filter\n",
      "Input #0, concat, from 'input_list.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: 117 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x354 [SAR 1593:1600 DAR 9:5], 117 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Output #0, mp4, to './sailorsvideo_new.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x354 [SAR 1593:1600 DAR 9:5], q=2-31, 117 kb/s, 30 fps, 30 tbr, 15360 tbn, 15360 tbc\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x558f26e1d280] Auto-inserting h264_mp4toannexb bitstream filter\n",
      "frame=  157 fps=0.0 q=-1.0 Lsize=     143kB time=00:00:05.13 bitrate= 227.8kbits/s speed=1.13e+03x    \n",
      "video:140kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.888910%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos concatenated successfully into sailorsvideo_new.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "output_folder = './videos/'\n",
    "output_file = 'concatenated_video_new.mp4'\n",
    "output_file = 'sailorsvideo_new.mp4'\n",
    "\n",
    "# Create a temporary text file to list the input videos\n",
    "temp_file = 'input_list.txt'\n",
    "with open(temp_file, 'w') as f:\n",
    "    for video in final_video_list:\n",
    "        f.write(f\"file '{os.path.join(output_folder, video)}'\\n\")\n",
    "\n",
    "# Construct the ffmpeg command\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-f', 'concat',\n",
    "    '-safe', '0',\n",
    "    '-i', temp_file,\n",
    "    '-c', 'copy',  # Stream copy for fast concatenation\n",
    "    '-y',    \n",
    "    os.path.join('./', output_file)\n",
    "]\n",
    "\n",
    "# Execute the ffmpeg command\n",
    "subprocess.run(ffmpeg_command)\n",
    "\n",
    "# Clean up the temporary file\n",
    "os.remove(temp_file)\n",
    "\n",
    "print(f\"Videos concatenated successfully into {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "164bc1d9-ee35-47c4-b0e6-638277e20b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"sailorsvideo_new.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_file = 'concatenated_video_new.mp4'\n",
    "# output_file = 'sailorsvideo_new.mp4'\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82131eb-7c87-4b8f-b38d-56b8101f8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "\n",
    "# Video('./videos/be_careful.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a4690-9fdf-4d10-86ae-e3aedd92df5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # !ffmpeg -i ./videos/sailor.mp4 -c:v libx264 -crf 23 -c:a aac -b:a 128k ./videos/sailor.mp4 -y\n",
    "\n",
    "# !ffmpeg -i ./videos/sailor.mp4 -r 30 ./videos/sailor.mp4\n",
    "# !ffmpeg -i ./videos/be_careful.mp4 -r 30 ./videos/be_careful.mp4"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
